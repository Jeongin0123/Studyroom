import torch
from torchvision import transforms
from PIL import Image
import io
import cv2
import numpy as np
import mediapipe as mp
from collections import deque

MODEL_PATH = "backend/best_model_Yawn_fold4.pth"

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸ import
from backend.best_model import YawnCNN

model = YawnCNN(num_classes=3)
model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
model.to(device)
model.eval()

# ì „ì²˜ë¦¬ (í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ Normalization ì¶”ê°€)
transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5],
                         std=[0.5, 0.5, 0.5])
])

# Mediapipe face detection (í…ŒìŠ¤íŠ¸ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ 0.4ë¡œ ì„¤ì •)
mp_face = mp.solutions.face_detection
face_detector = mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.4)

# ğŸ¯ ë‹¤ìˆ˜ê²° íˆ¬í‘œ ë²„í¼ (í…ŒìŠ¤íŠ¸ ì½”ë“œì™€ ë™ì¼)
prediction_buffer = deque(maxlen=10)

# ---------------------------
# ì–¼êµ´ + ì¡¸ìŒ íƒì§€ í•¨ìˆ˜
# ---------------------------
def predict_drowsiness(image_bytes: bytes):
    # ë°”ì´íŠ¸ â†’ OpenCV ì´ë¯¸ì§€
    img = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)

    # Mediapipe ì–¼êµ´ ê²€ì¶œ
    results = face_detector.process(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))

    if not results.detections:
        return "No Face"

    # ì²« ë²ˆì§¸ ì–¼êµ´ë§Œ ì‚¬ìš©
    det = results.detections[0]
    h, w, _ = img_cv.shape

    bbox = det.location_data.relative_bounding_box
    x1 = int(bbox.xmin * w)
    y1 = int(bbox.ymin * h)
    x2 = int((bbox.xmin + bbox.width) * w)
    y2 = int((bbox.ymin + bbox.height) * h)

    # ì–¼êµ´ crop
    face = img_cv[max(0, y1):y2, max(0, x1):x2]

    if face.size == 0:
        return "No Face"

    face_pil = Image.fromarray(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))

    # ì „ì²˜ë¦¬
    img_tensor = transform(face_pil).unsqueeze(0).to(device)

    # ì˜ˆì¸¡
    with torch.no_grad():
        output = model(img_tensor)
        probabilities = torch.softmax(output, dim=1)[0]
        
        # ğŸ”¬ ë””ë²„ê¹…: raw logits ì¶œë ¥
        print(f"ğŸ”¬ Raw logits: {output[0].cpu().numpy()}")
        
        # âš–ï¸ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¡°ì •
        # SleepyëŠ” ë¶€ìŠ¤íŠ¸ (8ë°° ì¦ê°€), Normal/Yawnì€ í˜ë„í‹° (60% ê°ì†Œ)
        adjusted_probs = probabilities.clone()
        adjusted_probs[0] *= 1.2  # Normal ì¦ê°€
        adjusted_probs[1] *= 1.0  # Sleepy ëŒ€í­ ì¦ê°€
        adjusted_probs[2] *= 0.6 # Yawn ê°ì†Œ
        
        # ì¡°ì •ëœ í™•ë¥ ë¡œ ì¬ì •ê·œí™”
        adjusted_probs = adjusted_probs / adjusted_probs.sum()
        
        # ì„ê³„ê°’ ê¸°ë°˜ ì˜ˆì¸¡: Yawnì€ ì¡°ì • í›„ì—ë„ 0.7 ì´ìƒì´ì–´ì•¼ í•¨
        predicted = torch.argmax(adjusted_probs).item()
        if predicted == 2 and adjusted_probs[2] < 0.7:
            # Yawn í™•ë¥ ì´ ì¶©ë¶„íˆ ë†’ì§€ ì•Šìœ¼ë©´ Normal ë˜ëŠ” Sleepy ì„ íƒ
            predicted = 0 if adjusted_probs[0] > adjusted_probs[1] else 1
        
        confidence = adjusted_probs[predicted].item()

    class_map = {0: "Normal", 1: "Sleepy", 2: "Yawn"}
    current_prediction = class_map[predicted]
    
    # ğŸ¯ ì‹¤ì‹œê°„ ì˜ˆì¸¡ (ë‹¤ìˆ˜ê²° íˆ¬í‘œ ë¹„í™œì„±í™”)
    # ë²„í¼ëŠ” ìœ ì§€í•˜ì§€ë§Œ ìµœì¢… ê²°ê³¼ëŠ” í˜„ì¬ í”„ë ˆì„ë§Œ ì‚¬ìš©
    prediction_buffer.append(current_prediction)
    final_result = current_prediction  # ì‹¤ì‹œê°„ ë°˜ì˜
    
    # ë””ë²„ê¹…ìš©: í™•ë¥  ì¶œë ¥
    print(f"ğŸ” Current: {current_prediction} (confidence: {confidence:.3f})")
    print(f"   Original: Normal={probabilities[0]:.3f}, Sleepy={probabilities[1]:.3f}, Yawn={probabilities[2]:.3f}")
    print(f"   Adjusted: Normal={adjusted_probs[0]:.3f}, Sleepy={adjusted_probs[1]:.3f}, Yawn={adjusted_probs[2]:.3f}")
    print(f"   âš¡ Real-time mode (no buffering)")
    
    return final_result