# langchain_practice/research_agent.py
"""
ê²€ìƒ‰ ë¦¬ì„œì¹˜ìš© ëª¨ë“ˆ (ë‹¨ìˆœ ì²´ì¸ ë²„ì „)
- DuckDuckGoë¡œ ì›¹ ê²€ìƒ‰ì„ í•˜ê³ 
- ê·¸ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë„£ì–´ì„œ LLMì´
  "ê°œë… ì„¤ëª… + [ìœ ì‚¬í•œ ê²€ìƒ‰ê²°ê³¼]" í˜•ì‹ìœ¼ë¡œ ë‹µì„ ë§Œë“¤ì–´ ì£¼ë„ë¡ í•¨.
"""

import os
from typing import Any, Dict, List

# ğŸ”¹ [ì¶”ê°€] .env íŒŒì¼ì—ì„œ OPENAI_API_KEY, OPENAI_MODEL ì½ì–´ì˜¤ê¸°
from dotenv import load_dotenv
load_dotenv()

from duckduckgo_search import DDGS

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser


# -----------------------------
# 1) ì›¹ ê²€ìƒ‰ í•¨ìˆ˜
# -----------------------------
def run_research_search(query: str) -> str:
    """
    DuckDuckGoì—ì„œ ì§ˆì˜ì–´ë¥¼ ê²€ìƒ‰í•´ì„œ
    "1. ì œëª© - URL" í˜•ì‹ìœ¼ë¡œ ìµœëŒ€ 3ê°œë¥¼ ë¬¸ìì—´ë¡œ ë§Œë“¤ì–´ ì¤€ë‹¤.
    """
    results: List[Dict[str, Any]] = []

    try:
        with DDGS() as ddgs:
            for r in ddgs.text(query, max_results=3):
                results.append(r)
    except Exception as e:
        return f"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    if not results:
        return "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    lines: List[str] = []
    for i, r in enumerate(results, start=1):
        title = r.get("title", "ì œëª© ì—†ìŒ")
        url = r.get("href") or r.get("url") or ""
        lines.append(f"{i}. {title} - {url}")

    return "\n".join(lines)


# -----------------------------
# 2) ë¦¬ì„œì¹˜ìš© LLM ì²´ì¸ ì •ì˜
# -----------------------------
PRIMARY_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")

llm = ChatOpenAI(
    model=PRIMARY_MODEL,
    temperature=0.3,
    timeout=60,
)

system_prompt = """
ë„ˆëŠ” ì‚¬ìš©ìì˜ ì •ë³´ íƒìƒ‰ì„ ë„ì™€ì£¼ëŠ” ì¡°êµì´ë‹¤.

ì—­í• :
1) ì‚¬ìš©ìê°€ ì–´ë–¤ ê°œë…/ì„œë¹„ìŠ¤/ì£¼ì œë¥¼ ë¬¼ì–´ë³´ë©´,
   ë¨¼ì € í•œêµ­ì–´ë¡œ ê·¸ ê°œë…ì„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ ì¤€ë‹¤.
2) ì´ì–´ì„œ í•œ ì¤„ ë„ìš°ê³ , ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ìœ ì‚¬í•œ ê²€ìƒ‰ê²°ê³¼ë¥¼ ë³´ì—¬ì¤€ë‹¤.

[ìœ ì‚¬í•œ ê²€ìƒ‰ê²°ê³¼]
1. ì œëª©1 - URL1
2. ì œëª©2 - URL2
3. ì œëª©3 - URL3

ê·œì¹™:
- ì•„ë˜ì— ì œê³µë˜ëŠ” ê²€ìƒ‰ê²°ê³¼ ë¬¸ìì—´ì„ ì°¸ê³ í•˜ì—¬ ë§í¬ë¥¼ ì„ ì •í•œë‹¤.
- ì„¤ëª… ë¶€ë¶„ì—ëŠ” URLì„ ë„£ì§€ ë§ê³ , ê°œë…/íŠ¹ì§• ìœ„ì£¼ë¡œ ì •ë¦¬í•œë‹¤.
- ë„ˆë¬´ ì¥í™©í•˜ì§€ ì•Šê²Œ í•µì‹¬ ìœ„ì£¼ë¡œ ì •ë¦¬í•œë‹¤.
"""

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        (
            "human",
            "ì‚¬ìš©ì ì§ˆë¬¸:\n{question}\n\n"
            "ì•„ë˜ëŠ” ì´ ì§ˆë¬¸ì— ëŒ€í•´ ì›¹ì—ì„œ ì°¾ì€ ê²€ìƒ‰ê²°ê³¼ ëª©ë¡ì´ë‹¤.\n"
            "[ê²€ìƒ‰ê²°ê³¼]\n{search_results}\n\n"
            "ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•´ì„œ ì—­í• ê³¼ í˜•ì‹ì— ë§ê²Œ ë‹µë³€í•´ ì¤˜.",
        ),
    ]
)

research_chain = prompt | llm | StrOutputParser()


# -----------------------------
# 3) ì™¸ë¶€ì—ì„œ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜
# -----------------------------
def get_research_answer(question: str) -> str:
    """
    langchain_chatbot.py ì—ì„œ í˜¸ì¶œí•˜ëŠ” ì§„ì… í•¨ìˆ˜.
    - question: ì‚¬ìš©ìì˜ ì§ˆë¬¸
    - ë°˜í™˜: ê°œë… ì„¤ëª… + [ìœ ì‚¬í•œ ê²€ìƒ‰ê²°ê³¼] í˜•ì‹ì˜ ë¬¸ìì—´
    """
    search_results = run_research_search(question)

    answer = research_chain.invoke(
        {
            "question": question,
            "search_results": search_results,
        }
    )
    return answer
